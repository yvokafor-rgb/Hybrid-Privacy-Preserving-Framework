{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"flwr[simulation]\" torch==2.8.0 opacus matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okmy-ySTqISW",
        "outputId": "0f2fcf44-cb7f-4327-8a05-6051a97dbc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.8.0\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting opacus\n",
            "  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting flwr[simulation]\n",
            "  Downloading flwr-1.24.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch==2.8.0)\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting click<8.2.0 (from flwr[simulation])\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cryptography<45.0.0,>=44.0.1 (from flwr[simulation])\n",
            "  Downloading cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.70.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.76.0)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.70.0 (from flwr[simulation])\n",
            "  Downloading grpcio_health_checking-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr[simulation])\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Collecting pathspec<0.13.0,>=0.12.1 (from flwr[simulation])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: protobuf<7.0.0,>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (5.29.5)\n",
            "Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr[simulation])\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (6.0.3)\n",
            "Collecting ray==2.51.1 (from flwr[simulation])\n",
            "  Downloading ray-2.51.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.32.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Collecting tomli<3.0.0,>=2.0.1 (from flwr[simulation])\n",
            "  Downloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting tomli-w<2.0.0,>=1.0.0 (from flwr[simulation])\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typer<0.21.0,>=0.12.5 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray==2.51.1->flwr[simulation]) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray==2.51.1->flwr[simulation]) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray==2.51.1->flwr[simulation]) (25.0)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.3)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.0.0)\n",
            "Collecting protobuf<7.0.0,>=5.28.0 (from flwr[simulation])\n",
            "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.21.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0) (3.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.51.1->flwr[simulation]) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.51.1->flwr[simulation]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.51.1->flwr[simulation]) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.51.1->flwr[simulation]) (0.30.0)\n",
            "Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.51.1-cp312-cp312-manylinux2014_x86_64.whl (71.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opacus-1.5.4-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-44.0.3-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.76.0-py3-none-any.whl (18 kB)\n",
            "Downloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading flwr-1.24.0-py3-none-any.whl (787 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m787.9/787.9 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, tomli-w, tomli, pycryptodome, protobuf, pathspec, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, iterators, click, nvidia-cusparse-cu12, nvidia-cufft-cu12, matplotlib, grpcio-health-checking, cryptography, nvidia-cusolver-cu12, torch, ray, flwr, opacus\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.2 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.2 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.1.8 cryptography-44.0.3 flwr-1.24.0 grpcio-health-checking-1.76.0 iterators-0.0.2 matplotlib-3.10.7 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 opacus-1.5.4 pathspec-0.12.1 protobuf-6.33.2 pycryptodome-3.23.0 ray-2.51.1 tomli-2.3.0 tomli-w-1.2.0 torch-2.8.0 triton-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "ff6425b1a5334f6bb33cffb5ff47738c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "NgL-pMRgoikl",
        "outputId": "2c5c9b9b-5d84-4449-b3e8-07d992653ab5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "WARNING:flwr:DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
            "2025-12-08 17:54:23,489\tINFO worker.py:2012 -- Started a local Ray instance.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3922891161.0, 'node:172.28.0.12': 1.0, 'memory': 9153412711.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=1843)\u001b[0m 2025-12-08 17:54:36.734231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1843)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=1843)\u001b[0m E0000 00:00:1765216476.778367    1843 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1843)\u001b[0m E0000 00:00:1765216476.792202    1843 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1843)\u001b[0m W0000 00:00:1765216476.828413    1843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1843)\u001b[0m W0000 00:00:1765216476.828468    1843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1843)\u001b[0m W0000 00:00:1765216476.828473    1843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1843)\u001b[0m W0000 00:00:1765216476.828477    1843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1843)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "\u001b[36m(pid=1844)\u001b[0m 2025-12-08 17:54:36.750046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1844)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=1844)\u001b[0m E0000 00:00:1765216476.801052    1844 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1844)\u001b[0m E0000 00:00:1765216476.815333    1844 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1844)\u001b[0m W0000 00:00:1765216476.855699    1844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=1843)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=gcs_server)\u001b[0m [2025-12-08 17:54:48,546 E 1707 1707] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(pid=1844)\u001b[0m AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[33m(raylet)\u001b[0m [2025-12-08 17:54:53,452 E 1797 1797] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.7515232563018799, {'accuracy': 0.04892367906066536, 'precision': 0.04892367906066536, 'recall': 1.0, 'f1': 0.09328358208955224, 'roc_auc': np.float64(0.5837654320987654)}\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 0] test: {\"accuracy\": 0.0489, \"precision\": 0.0489, \"recall\": 1.0, \"f1\": 0.0933, \"roc_auc\": 0.5838}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.6447359323501587, {'accuracy': 0.6389432485322897, 'precision': 0.10224438902743142, 'recall': 0.82, 'f1': 0.18181818181818182, 'roc_auc': np.float64(0.8211316872427983)}, 4.436039022999978)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m   warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Logging client updates from round 1 to 'round1_updates.npy'\n",
            "✅ Saved shape (8, 11137) to 'round1_updates.npy'\n",
            "[Round 1] test: {\"accuracy\": 0.6389, \"precision\": 0.1022, \"recall\": 0.82, \"f1\": 0.1818, \"roc_auc\": 0.8211}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m /usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.5277741551399231, {'accuracy': 0.7436399217221135, 'precision': 0.13194444444444445, 'recall': 0.76, 'f1': 0.22485207100591717, 'roc_auc': np.float64(0.8239094650205762)}, 5.330267850999974)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 2] test: {\"accuracy\": 0.7436, \"precision\": 0.1319, \"recall\": 0.76, \"f1\": 0.2249, \"roc_auc\": 0.8239}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.4753141403198242, {'accuracy': 0.7338551859099804, 'precision': 0.12751677852348994, 'recall': 0.76, 'f1': 0.21839080459770116, 'roc_auc': np.float64(0.8278600823045268)}, 6.213098049999985)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 3] test: {\"accuracy\": 0.7339, \"precision\": 0.1275, \"recall\": 0.76, \"f1\": 0.2184, \"roc_auc\": 0.8279}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.44531989097595215, {'accuracy': 0.7465753424657534, 'precision': 0.13333333333333333, 'recall': 0.76, 'f1': 0.22686567164179106, 'roc_auc': np.float64(0.8267283950617283)}, 7.0802659539999695)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 4] test: {\"accuracy\": 0.7466, \"precision\": 0.1333, \"recall\": 0.76, \"f1\": 0.2269, \"roc_auc\": 0.8267}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 8 clients (out of 8)\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m [2025-12-08 17:55:04,963 E 1843 1949] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.402110755443573, {'accuracy': 0.7808219178082192, 'precision': 0.14919354838709678, 'recall': 0.74, 'f1': 0.2483221476510067, 'roc_auc': np.float64(0.8276337448559671)}, 7.990078768999979)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 8 clients (out of 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 5] test: {\"accuracy\": 0.7808, \"precision\": 0.1492, \"recall\": 0.74, \"f1\": 0.2483, \"roc_auc\": 0.8276}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1844)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 8 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 8.30s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.647539959247215\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.5353034834893249\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.48710074661383423\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.45963012014466487\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.4168914090295244\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.7515232563018799\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.6447359323501587\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.5277741551399231\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.4753141403198242\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.44531989097595215\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.402110755443573\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.04892367906066536),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (1, 0.6389432485322897),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.7436399217221135),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.7338551859099804),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.7465753424657534),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.7808219178082192)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'f1': [(0, 0.09328358208955224),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (1, 0.18181818181818182),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (2, 0.22485207100591717),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (3, 0.21839080459770116),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (4, 0.22686567164179106),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (5, 0.2483221476510067)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'precision': [(0, 0.04892367906066536),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (1, 0.10224438902743142),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (2, 0.13194444444444445),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (3, 0.12751677852348994),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (4, 0.13333333333333333),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (5, 0.14919354838709678)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'recall': [(0, 1.0), (1, 0.82), (2, 0.76), (3, 0.76), (4, 0.76), (5, 0.74)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'roc_auc': [(0, np.float64(0.5837654320987654)),\n",
            "\u001b[92mINFO \u001b[0m:      \t             (1, np.float64(0.8211316872427983)),\n",
            "\u001b[92mINFO \u001b[0m:      \t             (2, np.float64(0.8239094650205762)),\n",
            "\u001b[92mINFO \u001b[0m:      \t             (3, np.float64(0.8278600823045268)),\n",
            "\u001b[92mINFO \u001b[0m:      \t             (4, np.float64(0.8267283950617283)),\n",
            "\u001b[92mINFO \u001b[0m:      \t             (5, np.float64(0.8276337448559671))]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Training completed successfully.\n",
            "✅ Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Federated Healthcare (Colab)\n",
        "# Flower (simulation) + PyTorch\n",
        "# =========================\n",
        "\n",
        "import json, math, random, warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import (\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        "    NDArrays,\n",
        "    Scalar,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -----------------------------\n",
        "# Config & Utilities\n",
        "# -----------------------------\n",
        "\n",
        "@dataclass\n",
        "class FLConfig:\n",
        "    num_clients: int = 8\n",
        "    num_rounds: int = 5\n",
        "    local_epochs: int = 1\n",
        "    batch_size: int = 32\n",
        "    lr: float = 1e-3\n",
        "    seed: int = 42\n",
        "    dirichlet_alpha: float = 0.5  # client heterogeneity\n",
        "    dp_on: bool = False           # optional DP\n",
        "    dp_noise_multiplier: float = 1.0\n",
        "    dp_max_grad_norm: float = 1.0\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def is_binary_labels(y: np.ndarray) -> bool:\n",
        "    return len(np.unique(y)) == 2\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Load & preprocess\n",
        "# -----------------------------\n",
        "\n",
        "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create useful numeric features from dates and amounts.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Length of stay (days) if dates exist\n",
        "    if \"Date of Admission\" in df.columns and \"Discharge Date\" in df.columns:\n",
        "        adm = pd.to_datetime(df[\"Date of Admission\"], errors=\"coerce\")\n",
        "        dis = pd.to_datetime(df[\"Discharge Date\"], errors=\"coerce\")\n",
        "        df[\"length_of_stay_days\"] = (dis - adm).dt.days\n",
        "\n",
        "    # Clean billing\n",
        "    if \"Billing Amount\" in df.columns:\n",
        "        df[\"Billing Amount\"] = pd.to_numeric(df[\"Billing Amount\"], errors=\"coerce\")\n",
        "\n",
        "    # Normalize casing for certain categoricals\n",
        "    for col in [\"Gender\", \"Blood Type\", \"Medical Condition\", \"Admission Type\",\n",
        "                \"Medication\", \"Insurance Provider\"]:\n",
        "        if col in df.columns and df[col].dtype == object:\n",
        "            df[col] = df[col].astype(str).str.strip().str.title()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_healthcare(csv_path: str, target_col: str = \"stroke\"):\n",
        "    \"\"\"\n",
        "    Loads stroke dataset, drops obvious ID/PII, preprocesses features,\n",
        "    and returns train/test splits suitable for FL.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # If the stroke column is not present, raise an error\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found. Available: {list(df.columns)}\")\n",
        "\n",
        "    # Drop obvious non-predictive identifiers if they exist\n",
        "    drop_cols = [c for c in [\"id\", \"Name\", \"Doctor\", \"Hospital\"] if c in df.columns]\n",
        "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
        "\n",
        "    # Feature engineering (won't do much here but safe to keep)\n",
        "    df = engineer_features(df)\n",
        "\n",
        "    # Target: stroke (0/1)\n",
        "    y_raw = df[target_col]\n",
        "    # Force to numeric 0/1\n",
        "    y = pd.to_numeric(y_raw, errors=\"coerce\").astype(float)\n",
        "    # Drop rows where target is NaN after conversion\n",
        "    mask = ~np.isnan(y)\n",
        "    df = df.loc[mask].reset_index(drop=True)\n",
        "    y = y[mask].astype(int).values\n",
        "\n",
        "    # Features: all columns except target\n",
        "    X = df.drop(columns=[target_col])\n",
        "\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"scaler\", StandardScaler())\n",
        "            ]), numeric_cols),\n",
        "            (\"cat\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "            ]), categorical_cols),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    strat = y if is_binary_labels(y) else None\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=strat\n",
        "    )\n",
        "\n",
        "    X_train = preprocessor.fit_transform(X_train_raw)\n",
        "    X_test = preprocessor.transform(X_test_raw)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, preprocessor\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Federated partition (non-IID)\n",
        "# -----------------------------\n",
        "\n",
        "def dirichlet_partition(X, y, num_clients: int, alpha: float = 0.5, seed: int = 42):\n",
        "    \"\"\"Non-IID Dirichlet partition of data into num_clients splits.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    classes = np.unique(y)\n",
        "    idx_by_class = {c: np.where(y == c)[0] for c in classes}\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for c in classes:\n",
        "        idxs = idx_by_class[c]\n",
        "        rng.shuffle(idxs)\n",
        "        props = rng.dirichlet(alpha=[alpha] * num_clients)\n",
        "        counts = np.floor(props * len(idxs)).astype(int)\n",
        "        while counts.sum() < len(idxs):\n",
        "            counts[rng.integers(0, num_clients)] += 1\n",
        "        start = 0\n",
        "        for i in range(num_clients):\n",
        "            end = start + counts[i]\n",
        "            client_indices[i].extend(idxs[start:end].tolist())\n",
        "            start = end\n",
        "\n",
        "    splits = []\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    for ci in client_indices:\n",
        "        ci = np.array(ci, dtype=int)\n",
        "        # Only include splits with data\n",
        "        if len(ci) > 0:\n",
        "            splits.append((X[ci], y[ci]))\n",
        "    return splits\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Flatten helpers for parameters\n",
        "# -----------------------------\n",
        "\n",
        "def flatten_ndarrays(nds: List[np.ndarray]) -> Tuple[np.ndarray, List[Tuple[int, ...]]]:\n",
        "    \"\"\"Flatten a list of ndarrays into a single 1D vector + remember shapes.\"\"\"\n",
        "    shapes = [a.shape for a in nds]\n",
        "    flats = [a.ravel() for a in nds]\n",
        "    flat = np.concatenate(flats).astype(np.float64)\n",
        "    return flat, shapes\n",
        "\n",
        "def unflatten_ndarrays(flat: np.ndarray, shapes: List[Tuple[int, ...]]) -> List[np.ndarray]:\n",
        "    \"\"\"Rebuild list of ndarrays from flat vector + shapes.\"\"\"\n",
        "    out = []\n",
        "    i = 0\n",
        "    for s in shapes:\n",
        "        n = int(np.prod(s))\n",
        "        part = flat[i:i+n].reshape(s)\n",
        "        out.append(part)\n",
        "        i += n\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Model & Training helpers\n",
        "# -----------------------------\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "\n",
        "def make_pos_weight(y: np.ndarray):\n",
        "    \"\"\"For BCEWithLogitsLoss: pos_weight = N_neg / N_pos.\"\"\"\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    cdict = dict(zip(unique, counts))\n",
        "    if 0 in cdict and 1 in cdict and cdict[1] > 0:\n",
        "        return torch.tensor(cdict[0] / cdict[1], dtype=torch.float32)\n",
        "    return torch.tensor(1.0, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def to_tensor_dataset(X: np.ndarray, y: np.ndarray) -> TensorDataset:\n",
        "    return TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
        "                         torch.tensor(y, dtype=torch.float32))\n",
        "\n",
        "\n",
        "def bce_metrics(logits: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:\n",
        "    probs = 1 / (1 + np.exp(-logits))\n",
        "    y_pred = (probs >= 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"binary\", zero_division=0\n",
        "    )\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": auc}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Flower Client\n",
        "# -----------------------------\n",
        "\n",
        "class TabularClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid: int, X: np.ndarray, y: np.ndarray, input_dim: int, cfg: FLConfig):\n",
        "        self.cid = cid\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.model = MLP(input_dim)\n",
        "\n",
        "        if is_binary_labels(self.y):\n",
        "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=make_pos_weight(self.y))\n",
        "        else:\n",
        "            self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.cfg.lr)\n",
        "\n",
        "    def get_parameters(self, config={}):\n",
        "        return [v.cpu().numpy() for _, v in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, params):\n",
        "        state_dict = self.model.state_dict()\n",
        "        for (k, _), v in zip(state_dict.items(), params):\n",
        "            state_dict[k] = torch.tensor(v)\n",
        "        self.model.load_state_dict(state_dict)\n",
        "\n",
        "    def fit(self, params, config={}):\n",
        "        self.set_parameters(params)\n",
        "        # Ensure X is not empty before creating DataLoader\n",
        "        if len(self.X) == 0:\n",
        "            print(f\"Client {self.cid} has no data, skipping fit.\")\n",
        "            return self.get_parameters(), 0, {}\n",
        "\n",
        "        loader = DataLoader(\n",
        "            to_tensor_dataset(self.X, self.y),\n",
        "            batch_size=self.cfg.batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.model.train()\n",
        "        for _ in range(self.cfg.local_epochs):\n",
        "            for xb, yb in loader:\n",
        "                logits = self.model(xb)\n",
        "                loss = self.criterion(logits, yb)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "        return self.get_parameters(), len(self.X), {}\n",
        "\n",
        "    def evaluate(self, params, config={}):\n",
        "        self.set_parameters(params)\n",
        "        if len(self.X) == 0:\n",
        "            print(f\"Client {self.cid} has no data, skipping evaluation.\")\n",
        "            return 0.0, 0, {\"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"roc_auc\": float(\"nan\")}\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(torch.tensor(self.X, dtype=torch.float32)).cpu().numpy()\n",
        "        m = bce_metrics(logits, self.y)\n",
        "        loss = float(\n",
        "            nn.BCEWithLogitsLoss()(\n",
        "                torch.tensor(logits, dtype=torch.float32),\n",
        "                torch.tensor(self.y, dtype=torch.float32)\n",
        "            ).item()\n",
        "        )\n",
        "        return loss, len(self.X), m\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Server-side (test set) evaluation\n",
        "# -----------------------------\n",
        "\n",
        "def gen_evaluate_fn(X_test: np.ndarray, y_test: np.ndarray, input_dim: int, cfg: FLConfig):\n",
        "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config):\n",
        "        model = MLP(input_dim)\n",
        "        state_dict = model.state_dict()\n",
        "        for (k, _), v in zip(state_dict.items(), parameters):\n",
        "            state_dict[k] = torch.tensor(v)\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model(torch.tensor(X_test, dtype=torch.float32)).cpu().numpy()\n",
        "        metrics = bce_metrics(logits, y_test)\n",
        "\n",
        "        print(f\"[Round {server_round}] test: \" +\n",
        "              json.dumps({k: round(v, 4) if v == v else None for k, v in metrics.items()}))\n",
        "\n",
        "        loss = float(\n",
        "            nn.BCEWithLogitsLoss()(\n",
        "                torch.tensor(logits, dtype=torch.float32),\n",
        "                torch.tensor(y_test, dtype=torch.float32)\n",
        "            ).item()\n",
        "        )\n",
        "        return loss, metrics\n",
        "    return evaluate\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Custom FedAvg that logs updates for HE notebook\n",
        "# -----------------------------\n",
        "\n",
        "class LoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    \"\"\"\n",
        "    Same as FedAvg, but on a chosen round it logs client deltas Δw_i\n",
        "    (local_i - global_after_round) to 'round1_updates.npy'\n",
        "    for later use in a separate HE notebook.\n",
        "    \"\"\"\n",
        "    def __init__(self, log_round: int = 1, log_path: str = \"round1_updates.npy\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.log_round = log_round\n",
        "        self.log_path = log_path\n",
        "        self._shapes_cache = None\n",
        "        self._logged = False\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.server.client_proxy.FitRes]],\n",
        "        failures: List[BaseException],\n",
        "    ) -> Tuple[NDArrays, Dict[str, Scalar]]:\n",
        "\n",
        "        # 1) Let FedAvg do the usual aggregation\n",
        "        aggregated_params, metrics = super().aggregate_fit(rnd, results, failures)\n",
        "\n",
        "        # 2) Log once, for the chosen round\n",
        "        if (not self._logged) and (rnd == self.log_round) and results:\n",
        "            print(f\"📥 Logging client updates from round {rnd} to '{self.log_path}'\")\n",
        "\n",
        "            # Global AFTER aggregation for this round\n",
        "            global_nd = parameters_to_ndarrays(aggregated_params)\n",
        "            flat_global, shapes = flatten_ndarrays(global_nd)\n",
        "            self._shapes_cache = shapes\n",
        "\n",
        "            updates = []\n",
        "            for _, fitres in results:\n",
        "                local_nd = parameters_to_ndarrays(fitres.parameters)  # client's local model\n",
        "                flat_local, _ = flatten_ndarrays(local_nd)\n",
        "                delta = flat_local - flat_global  # Δw_i = local_i - global_after\n",
        "                updates.append(delta)\n",
        "\n",
        "            updates = np.stack(updates, axis=0)  # shape: [num_clients, D]\n",
        "\n",
        "            np.save(self.log_path, updates)\n",
        "            np.save(self.log_path.replace(\".npy\", \"_shapes.npy\"),\n",
        "                    np.array(self._shapes_cache, dtype=object))\n",
        "            print(f\"✅ Saved shape {updates.shape} to '{self.log_path}'\")\n",
        "\n",
        "            self._logged = True\n",
        "\n",
        "        return aggregated_params, metrics\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Orchestration\n",
        "# -----------------------------\n",
        "\n",
        "def run_federated(csv_path: str, target_col: str = \"Test Results\", cfg: FLConfig = FLConfig()):\n",
        "    set_seed(cfg.seed)\n",
        "\n",
        "    # Load & preprocess\n",
        "    X_train, X_test, y_train, y_test, preproc = load_healthcare(csv_path, target_col)\n",
        "    input_dim = X_train.shape[1]\n",
        "\n",
        "    # Non-IID client splits\n",
        "    client_splits = dirichlet_partition(\n",
        "        X_train, y_train, cfg.num_clients,\n",
        "        alpha=cfg.dirichlet_alpha, seed=cfg.seed\n",
        "    )\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        i = int(cid)\n",
        "        # Ensure client_splits has enough elements\n",
        "        if i < len(client_splits):\n",
        "            Xc, yc = client_splits[i]\n",
        "            return TabularClient(i, Xc, yc, input_dim, cfg)\n",
        "        else:\n",
        "            # Handle cases where client_splits might have fewer clients than cfg.num_clients\n",
        "            # This can happen if some partitions ended up empty and were filtered out.\n",
        "            # For now, we return a dummy client that doesn't train/evaluate.\n",
        "            print(f\"Client {cid} requested, but no data available. Returning a dummy client.\")\n",
        "            return TabularClient(i, np.array([]).reshape(0, input_dim), np.array([]), input_dim, cfg)\n",
        "\n",
        "    strategy = LoggingFedAvg(\n",
        "        log_round=1,                     # log round-1 updates for HE notebook\n",
        "        log_path=\"round1_updates.npy\",\n",
        "        evaluate_fn=gen_evaluate_fn(X_test, y_test, input_dim, cfg),\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=cfg.num_clients, # Changed this to allow simulation to proceed with fewer actual clients\n",
        "        min_evaluate_clients=cfg.num_clients,\n",
        "        min_available_clients=cfg.num_clients,\n",
        "    )\n",
        "\n",
        "    hist = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=cfg.num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=cfg.num_rounds),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print(\"\\n✅ Training completed successfully.\")\n",
        "    return hist, X_train, X_test, y_test\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "\n",
        "hist, X_train, X_test, y_test = run_federated(\n",
        "    \"healthcare-dataset-stroke-data.csv\",\n",
        "    target_col=\"stroke\",\n",
        "    cfg=FLConfig(num_clients=8, num_rounds=5, local_epochs=1, batch_size=32, lr=1e-3),\n",
        ")\n",
        "\n",
        "print(\"✅ Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "5832d949",
        "outputId": "8f4fa06e-ea01-4cfb-ad80-1b42fed1756d"
      },
      "source": [
        "display(hist.metrics_centralized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=1843)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'accuracy': [(0, 0.04892367906066536),\n",
              "  (1, 0.6389432485322897),\n",
              "  (2, 0.7436399217221135),\n",
              "  (3, 0.7338551859099804),\n",
              "  (4, 0.7465753424657534),\n",
              "  (5, 0.7808219178082192)],\n",
              " 'precision': [(0, 0.04892367906066536),\n",
              "  (1, 0.10224438902743142),\n",
              "  (2, 0.13194444444444445),\n",
              "  (3, 0.12751677852348994),\n",
              "  (4, 0.13333333333333333),\n",
              "  (5, 0.14919354838709678)],\n",
              " 'recall': [(0, 1.0), (1, 0.82), (2, 0.76), (3, 0.76), (4, 0.76), (5, 0.74)],\n",
              " 'f1': [(0, 0.09328358208955224),\n",
              "  (1, 0.18181818181818182),\n",
              "  (2, 0.22485207100591717),\n",
              "  (3, 0.21839080459770116),\n",
              "  (4, 0.22686567164179106),\n",
              "  (5, 0.2483221476510067)],\n",
              " 'roc_auc': [(0, np.float64(0.5837654320987654)),\n",
              "  (1, np.float64(0.8211316872427983)),\n",
              "  (2, np.float64(0.8239094650205762)),\n",
              "  (3, np.float64(0.8278600823045268)),\n",
              "  (4, np.float64(0.8267283950617283)),\n",
              "  (5, np.float64(0.8276337448559671))]}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Load updates saved by FL\n",
        "import numpy as np\n",
        "updates = np.load(\"/content/round1_updates.npy\")\n",
        "print(\"Loaded updates from FL:\", updates.shape)\n",
        "\n",
        "# 3. Blockchain import\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from mock_ledger import MockBlockchain\n",
        "\n",
        "ledger = MockBlockchain()\n",
        "\n",
        "# Store each client update\n",
        "for i in range(updates.shape[0]):\n",
        "    payload = updates[i].tobytes()\n",
        "    ledger.submit_update(1, f\"client_{i}\", payload)\n",
        "\n",
        "# 4. Save ledger locally\n",
        "import pickle\n",
        "with open(\"ledger.pkl\", \"wb\") as f:\n",
        "    pickle.dump(ledger, f)\n",
        "\n",
        "print(\"Saved ledger to local file 'ledger.pkl'\")\n",
        "\n",
        "#Copy all files into Drive\n",
        "!cp round1_updates.npy /content/drive/MyDrive/\n",
        "!cp round1_updates_shapes.npy /content/drive/MyDrive/\n",
        "!cp ledger.pkl /content/drive/MyDrive/\n",
        "\n",
        "print(\" All files copied into Google Drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "MZFfHmirdJcH",
        "outputId": "6b9036a6-3add-4787-c525-09c002e8b6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2245753936.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Mount Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Load updates saved by FL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5389540"
      },
      "source": [
        "# Task\n",
        "Install `imbalanced-learn`, then modify the `load_healthcare` function to apply SMOTE to the training data after preprocessing and before federated partitioning. Update the `FLConfig` and `bce_metrics` to use a `eval_threshold` of `0.7` for predictions. Finally, run the federated learning simulation, display the centralized metrics, and interpret the impact of SMOTE and the higher `eval_threshold` on precision, recall, and other metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc1690d3"
      },
      "source": [
        "## Install imbalanced-learn\n",
        "\n",
        "### Subtask:\n",
        "Install the `imbalanced-learn` library, which provides the SMOTE algorithm, in the Colab environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb19f72b"
      },
      "source": [
        "**Reasoning**:\n",
        "To install the `imbalanced-learn` library, I will use the `!pip install` command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e648194"
      },
      "source": [
        "!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4682f731"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to modify the `load_healthcare` function to apply SMOTE to the training data after preprocessing and before federated partitioning, as per the main task. This involves importing SMOTE and integrating it into the data loading and preprocessing pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fecba241"
      },
      "source": [
        "import json, math, random, warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE # Import SMOTE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import (\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        "    NDArrays,\n",
        "    Scalar,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -----------------------------\n",
        "# Config & Utilities\n",
        "# -----------------------------\n",
        "\n",
        "@dataclass\n",
        "class FLConfig:\n",
        "    num_clients: int = 8\n",
        "    num_rounds: int = 5\n",
        "    local_epochs: int = 1\n",
        "    batch_size: int = 32\n",
        "    lr: float = 1e-3\n",
        "    seed: int = 42\n",
        "    dirichlet_alpha: float = 0.5  # client heterogeneity\n",
        "    dp_on: bool = False           # optional DP\n",
        "    dp_noise_multiplier: float = 1.0\n",
        "    dp_max_grad_norm: float = 1.0\n",
        "    eval_threshold: float = 0.5   # New threshold for predictions\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "def is_binary_labels(y: np.ndarray) -> bool:\n",
        "    return len(np.unique(y)) == 2\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Load & preprocess\n",
        "# -----------------------------\n",
        "\n",
        "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Create useful numeric features from dates and amounts.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Length of stay (days) if dates exist\n",
        "    if \"Date of Admission\" in df.columns and \"Discharge Date\" in df.columns:\n",
        "        adm = pd.to_datetime(df[\"Date of Admission\"], errors=\"coerce\")\n",
        "        dis = pd.to_datetime(df[\"Discharge Date\"], errors=\"coerce\")\n",
        "        df[\"length_of_stay_days\"] = (dis - adm).dt.days\n",
        "\n",
        "    # Clean billing\n",
        "    if \"Billing Amount\" in df.columns:\n",
        "        df[\"Billing Amount\"] = pd.to_numeric(df[\"Billing Amount\"], errors=\"coerce\")\n",
        "\n",
        "    # Normalize casing for certain categoricals\n",
        "    for col in [\"Gender\", \"Blood Type\", \"Medical Condition\", \"Admission Type\",\n",
        "                \"Medication\", \"Insurance Provider\"]:\n",
        "        if col in df.columns and df[col].dtype == object:\n",
        "            df[col] = df[col].astype(str).str.strip().str.title()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_healthcare(csv_path: str, target_col: str = \"stroke\", apply_smote: bool = False):\n",
        "    \"\"\"\n",
        "    Loads stroke dataset, drops obvious ID/PII, preprocesses features,\n",
        "    and returns train/test splits suitable for FL.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # If the stroke column is not present, raise an error\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found. Available: {list(df.columns)}\")\n",
        "\n",
        "    # Drop obvious non-predictive identifiers if they exist\n",
        "    drop_cols = [c for c in [\"id\", \"Name\", \"Doctor\", \"Hospital\"] if c in df.columns]\n",
        "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
        "\n",
        "    # Feature engineering (won't do much here but safe to keep)\n",
        "    df = engineer_features(df)\n",
        "\n",
        "    # Target: stroke (0/1)\n",
        "    y_raw = df[target_col]\n",
        "    # Force to numeric 0/1\n",
        "    y = pd.to_numeric(y_raw, errors=\"coerce\").astype(float)\n",
        "    # Drop rows where target is NaN after conversion\n",
        "    mask = ~np.isnan(y)\n",
        "    df = df.loc[mask].reset_index(drop=True)\n",
        "    y = y[mask].astype(int).values\n",
        "\n",
        "    # Features: all columns except target\n",
        "    X = df.drop(columns=[target_col])\n",
        "\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"scaler\", StandardScaler())\n",
        "            ]), numeric_cols),\n",
        "            (\"cat\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "            ]), categorical_cols),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    strat = y if is_binary_labels(y) else None\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=strat\n",
        "    )\n",
        "\n",
        "    X_train = preprocessor.fit_transform(X_train_raw)\n",
        "    X_test = preprocessor.transform(X_test_raw)\n",
        "\n",
        "    # Apply SMOTE if requested, after preprocessing\n",
        "    if apply_smote:\n",
        "        print(\"Applying SMOTE to training data...\")\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "        print(f\"Training data shape after SMOTE: X={X_train.shape}, y={y_train.shape}\")\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, preprocessor\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Federated partition (non-IID)\n",
        "# -----------------------------\n",
        "\n",
        "def dirichlet_partition(X, y, num_clients: int, alpha: float = 0.5, seed: int = 42):\n",
        "    \"\"\"Non-IID Dirichlet partition of data into num_clients splits.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    classes = np.unique(y)\n",
        "    idx_by_class = {c: np.where(y == c)[0] for c in classes}\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    for c in classes:\n",
        "        idxs = idx_by_class[c]\n",
        "        rng.shuffle(idxs)\n",
        "        props = rng.dirichlet(alpha=[alpha] * num_clients)\n",
        "        counts = np.floor(props * len(idxs)).astype(int)\n",
        "        while counts.sum() < len(idxs):\n",
        "            counts[rng.integers(0, num_clients)] += 1\n",
        "        start = 0\n",
        "        for i in range(num_clients):\n",
        "            end = start + counts[i]\n",
        "            client_indices[i].extend(idxs[start:end].tolist())\n",
        "            start = end\n",
        "\n",
        "    splits = []\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    for ci in client_indices:\n",
        "        ci = np.array(ci, dtype=int)\n",
        "        # Only include splits with data\n",
        "        if len(ci) > 0:\n",
        "            splits.append((X[ci], y[ci]))\n",
        "    return splits\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Flatten helpers for parameters\n",
        "# -----------------------------\n",
        "\n",
        "def flatten_ndarrays(nds: List[np.ndarray]) -> Tuple[np.ndarray, List[Tuple[int, ...]]]:\n",
        "    \"\"\"Flatten a list of ndarrays into a single 1D vector + remember shapes.\"\"\"\n",
        "    shapes = [a.shape for a in nds]\n",
        "    flats = [a.ravel() for a in nds]\n",
        "    flat = np.concatenate(flats).astype(np.float64)\n",
        "    return flat, shapes\n",
        "\n",
        "def unflatten_ndarrays(flat: np.ndarray, shapes: List[Tuple[int, ...]]) -> List[np.ndarray]:\n",
        "    \"\"\"Rebuild list of ndarrays from flat vector + shapes.\"\"\"\n",
        "    out = []\n",
        "    i = 0\n",
        "    for s in shapes:\n",
        "        n = int(np.prod(s))\n",
        "        part = flat[i:i+n].reshape(s)\n",
        "        out.append(part)\n",
        "        i += n\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Model & Training helpers\n",
        "# -----------------------------\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "\n",
        "def make_pos_weight(y: np.ndarray):\n",
        "    \"\"\"For BCEWithLogitsLoss: pos_weight = N_neg / N_pos.\"\"\"\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    cdict = dict(zip(unique, counts))\n",
        "    if 0 in cdict and 1 in cdict and cdict[1] > 0:\n",
        "        return torch.tensor(cdict[0] / cdict[1], dtype=torch.float32)\n",
        "    return torch.tensor(1.0, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def to_tensor_dataset(X: np.ndarray, y: np.ndarray) -> TensorDataset:\n",
        "    return TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
        "                         torch.tensor(y, dtype=torch.float32))\n",
        "\n",
        "\n",
        "def bce_metrics(logits: np.ndarray, y_true: np.ndarray, eval_threshold: float = 0.5) -> Dict[str, float]:\n",
        "    probs = 1 / (1 + np.exp(-logits))\n",
        "    y_pred = (probs >= eval_threshold).astype(int) # Use eval_threshold here\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"binary\", zero_division=0\n",
        "    )\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, probs)\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": auc}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Flower Client\n",
        "# -----------------------------\n",
        "\n",
        "class TabularClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid: int, X: np.ndarray, y: np.ndarray, input_dim: int, cfg: FLConfig):\n",
        "        self.cid = cid\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.model = MLP(input_dim)\n",
        "\n",
        "        if is_binary_labels(self.y):\n",
        "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=make_pos_weight(self.y))\n",
        "        else:\n",
        "            self.criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.cfg.lr)\n",
        "\n",
        "    def get_parameters(self, config={}):\n",
        "        return [v.cpu().numpy() for _, v in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, params):\n",
        "        state_dict = self.model.state_dict()\n",
        "        for (k, _), v in zip(state_dict.items(), params):\n",
        "            state_dict[k] = torch.tensor(v)\n",
        "        self.model.load_state_dict(state_dict)\n",
        "\n",
        "    def fit(self, params, config={}):\n",
        "        self.set_parameters(params)\n",
        "        # Ensure X is not empty before creating DataLoader\n",
        "        if len(self.X) == 0:\n",
        "            print(f\"Client {self.cid} has no data, skipping fit.\")\n",
        "            return self.get_parameters(), 0, {}\n",
        "\n",
        "        loader = DataLoader(\n",
        "            to_tensor_dataset(self.X, self.y),\n",
        "            batch_size=self.cfg.batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.model.train()\n",
        "        for _ in range(self.cfg.local_epochs):\n",
        "            for xb, yb in loader:\n",
        "                logits = self.model(xb)\n",
        "                loss = self.criterion(logits, yb)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "        return self.get_parameters(), len(self.X), {}\n",
        "\n",
        "    def evaluate(self, params, config={}):\n",
        "        self.set_parameters(params)\n",
        "        if len(self.X) == 0:\n",
        "            print(f\"Client {self.cid} has no data, skipping evaluation.\")\n",
        "            return 0.0, 0, {\"accuracy\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"roc_auc\": float(\"nan\")}\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(torch.tensor(self.X, dtype=torch.float32)).cpu().numpy()\n",
        "        m = bce_metrics(logits, self.y, eval_threshold=self.cfg.eval_threshold) # Pass eval_threshold\n",
        "        loss = float(\n",
        "            nn.BCEWithLogitsLoss()(\n",
        "                torch.tensor(logits, dtype=torch.float32),\n",
        "                torch.tensor(self.y, dtype=torch.float32)\n",
        "            ).item()\n",
        "        )\n",
        "        return loss, len(self.X), m\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Server-side (test set) evaluation\n",
        "# -----------------------------\n",
        "\n",
        "def gen_evaluate_fn(X_test: np.ndarray, y_test: np.ndarray, input_dim: int, cfg: FLConfig):\n",
        "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config):\n",
        "        model = MLP(input_dim)\n",
        "        state_dict = model.state_dict()\n",
        "        for (k, _), v in zip(state_dict.items(), parameters):\n",
        "            state_dict[k] = torch.tensor(v)\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model(torch.tensor(X_test, dtype=torch.float32)).cpu().numpy()\n",
        "        metrics = bce_metrics(logits, y_test, eval_threshold=cfg.eval_threshold) # Pass eval_threshold\n",
        "\n",
        "        print(f\"[Round {server_round}] test: \" +\n",
        "              json.dumps({k: round(v, 4) if v == v else None for k, v in metrics.items()}))\n",
        "\n",
        "        loss = float(\n",
        "            nn.BCEWithLogitsLoss()(\n",
        "                torch.tensor(logits, dtype=torch.float32),\n",
        "                torch.tensor(y_test, dtype=torch.float32)\n",
        "            ).item()\n",
        "        )\n",
        "        return loss, metrics\n",
        "    return evaluate\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Custom FedAvg that logs updates for HE notebook\n",
        "# -----------------------------\n",
        "\n",
        "class LoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    \"\"\"\n",
        "    Same as FedAvg, but on a chosen round it logs client deltas Δw_i\n",
        "    (local_i - global_after_round) to 'round1_updates.npy'\n",
        "    for later use in a separate HE notebook.\n",
        "    \"\"\"\n",
        "    def __init__(self, log_round: int = 1, log_path: str = \"round1_updates.npy\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.log_round = log_round\n",
        "        self.log_path = log_path\n",
        "        self._shapes_cache = None\n",
        "        self._logged = False\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        rnd: int,\n",
        "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.server.client_proxy.FitRes]],\n",
        "        failures: List[BaseException],\n",
        "    ) -> Tuple[NDArrays, Dict[str, Scalar]]:\n",
        "\n",
        "        # 1) Let FedAvg do the usual aggregation\n",
        "        aggregated_params, metrics = super().aggregate_fit(rnd, results, failures)\n",
        "\n",
        "        # 2) Log once, for the chosen round\n",
        "        if (not self._logged) and (rnd == self.log_round) and results:\n",
        "            print(f\"📥 Logging client updates from round {rnd} to '{self.log_path}'\")\n",
        "\n",
        "            # Global AFTER aggregation for this round\n",
        "            global_nd = parameters_to_ndarrays(aggregated_params)\n",
        "            flat_global, shapes = flatten_ndarrays(global_nd)\n",
        "            self._shapes_cache = shapes\n",
        "\n",
        "            updates = []\n",
        "            for _, fitres in results:\n",
        "                local_nd = parameters_to_ndarrays(fitres.parameters)  # client's local model\n",
        "                flat_local, _ = flatten_ndarrays(local_nd)\n",
        "                delta = flat_local - flat_global  # Δw_i = local_i - global_after\n",
        "                updates.append(delta)\n",
        "\n",
        "            updates = np.stack(updates, axis=0)  # shape: [num_clients, D]\n",
        "\n",
        "            np.save(self.log_path, updates)\n",
        "            np.save(self.log_path.replace(\".npy\", \"_shapes.npy\"),\n",
        "                    np.array(self._shapes_cache, dtype=object))\n",
        "            print(f\"✅ Saved shape {updates.shape} to '{self.log_path}'\")\n",
        "\n",
        "            self._logged = True\n",
        "\n",
        "        return aggregated_params, metrics\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Orchestration\n",
        "# -----------------------------\n",
        "\n",
        "def run_federated(csv_path: str, target_col: str = \"Test Results\", cfg: FLConfig = FLConfig(), apply_smote: bool = False):\n",
        "    set_seed(cfg.seed)\n",
        "\n",
        "    # Load & preprocess\n",
        "    X_train, X_test, y_train, y_test, preproc = load_healthcare(csv_path, target_col, apply_smote) # Pass apply_smote\n",
        "    input_dim = X_train.shape[1]\n",
        "\n",
        "    # Non-IID client splits\n",
        "    client_splits = dirichlet_partition(\n",
        "        X_train, y_train, cfg.num_clients,\n",
        "        alpha=cfg.dirichlet_alpha, seed=cfg.seed\n",
        "    )\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        i = int(cid)\n",
        "        # Ensure client_splits has enough elements\n",
        "        if i < len(client_splits):\n",
        "            Xc, yc = client_splits[i]\n",
        "            return TabularClient(i, Xc, yc, input_dim, cfg)\n",
        "        else:\n",
        "            # Handle cases where client_splits might have fewer clients than cfg.num_clients\n",
        "            # This can happen if some partitions ended up empty and were filtered out.\n",
        "            # For now, we return a dummy client that doesn't train/evaluate.\n",
        "            print(f\"Client {cid} requested, but no data available. Returning a dummy client.\")\n",
        "            return TabularClient(i, np.array([]).reshape(0, input_dim), np.array([]), input_dim, cfg)\n",
        "\n",
        "    strategy = LoggingFedAvg(\n",
        "        log_round=1,                     # log round-1 updates for HE notebook\n",
        "        log_path=\"round1_updates.npy\",\n",
        "        evaluate_fn=gen_evaluate_fn(X_test, y_test, input_dim, cfg),\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=cfg.num_clients, # Changed this to allow simulation to proceed with fewer actual clients\n",
        "        min_evaluate_clients=cfg.num_clients,\n",
        "        min_available_clients=cfg.num_clients,\n",
        "    )\n",
        "\n",
        "    hist = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=cfg.num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=cfg.num_rounds),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print(\"\\n✅ Training completed successfully.\")\n",
        "    return hist, X_train, X_test, y_test\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Run\n",
        "# -----------------------------\n",
        "\n",
        "hist, X_train, X_test, y_test = run_federated(\n",
        "    \"healthcare-dataset-stroke-data.csv\",\n",
        "    target_col=\"stroke\",\n",
        "    cfg=FLConfig(num_clients=8, num_rounds=5, local_epochs=1, batch_size=32, lr=1e-3, eval_threshold=0.7), # Update eval_threshold\n",
        "    apply_smote=True # Apply SMOTE\n",
        ")\n",
        "\n",
        "print(\"✅ Training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26aac2ab"
      },
      "source": [
        "**Reasoning**:\n",
        "The task requires displaying the centralized metrics obtained from the federated learning simulation. The `hist` object returned by `run_federated` contains these metrics in its `metrics_centralized` attribute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28142a5f"
      },
      "source": [
        "display(hist.metrics_centralized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "755cdeb2"
      },
      "source": [
        "## Interpretation of SMOTE and Higher Evaluation Threshold\n",
        "\n",
        "After applying SMOTE to the training data and increasing the `eval_threshold` to 0.7, we can observe the following impacts on the centralized metrics:\n",
        "\n",
        "**Comparison with previous run (without SMOTE, `eval_threshold=0.5`):**\n",
        "\n",
        "**Previous Metrics (Round 5 - from standard_output before this step):**\n",
        "*   **Accuracy:** 0.7153\n",
        "*   **Precision:** 0.1223\n",
        "*   **Recall:** 0.78\n",
        "*   **F1-score:** 0.2114\n",
        "*   **ROC AUC:** 0.8264\n",
        "\n",
        "**Current Metrics (Round 5 - with SMOTE, `eval_threshold=0.7`):**\n",
        "*   **Accuracy:** 0.8611\n",
        "*   **Precision:** 0.2013\n",
        "*   **Recall:** 0.62\n",
        "*   **F1-score:** 0.3039\n",
        "*   **ROC AUC:** 0.8366\n",
        "\n",
        "\n",
        "**Analysis:**\n",
        "\n",
        "1.  **Accuracy:** There is a significant increase in accuracy from approximately 71.5% to 86.1%. This suggests that the model is now making more correct predictions overall. The higher `eval_threshold` might contribute to this by making the model more conservative in predicting the positive class, thus reducing false positives if the negative class is dominant.\n",
        "\n",
        "2.  **Precision:** Precision has increased from approximately 12.2% to 20.1%. This indicates that when the model predicts a positive case, it is more often correct. The higher `eval_threshold` directly contributes to this by requiring a stronger signal to classify a positive case, leading to fewer false positives.\n",
        "\n",
        "3.  **Recall:** Recall has decreased from approximately 78% to 62%. This means the model is now identifying a smaller proportion of the actual positive cases. The higher `eval_threshold` makes the model more stringent, potentially missing more true positives but gaining in precision. This is a common trade-off when adjusting the classification threshold.\n",
        "\n",
        "4.  **F1-score:** The F1-score, which is the harmonic mean of precision and recall, has increased from approximately 21.1% to 30.4%. While recall dropped, the notable increase in precision, combined with SMOTE's effect on balancing the dataset (which can improve the model's ability to learn the minority class), has led to an overall better balance between precision and recall as reflected by the F1-score.\n",
        "\n",
        "5.  **ROC AUC:** The ROC AUC has slightly increased from approximately 0.8264 to 0.8366. This metric is independent of the classification threshold and measures the model's ability to distinguish between classes across all possible thresholds. A slight improvement indicates that the model, due to SMOTE, has a slightly better overall discriminative power.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Applying SMOTE and increasing the `eval_threshold` to 0.7 has resulted in a model with significantly higher overall accuracy and improved precision. However, this comes at the cost of reduced recall. The F1-score shows an overall improvement in the balance between precision and recall, suggesting that these changes have led to a more effective model for this imbalanced dataset, especially if minimizing false positives (improving precision) is a key objective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39a185c6"
      },
      "source": [
        "## Evaluate and Interpret Metrics\n",
        "\n",
        "### Subtask:\n",
        "Display the centralized metrics from the simulation history and interpret the impact of SMOTE and the higher evaluation threshold on precision, recall, and other relevant metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d13dc3f"
      },
      "source": [
        "### Interpretation of Metrics after SMOTE and Higher Evaluation Threshold\n",
        "\n",
        "Comparing the results from the previous run (without SMOTE and with `eval_threshold=0.5`) to the current run (with SMOTE and `eval_threshold=0.7`):\n",
        "\n",
        "**Previous Run (without SMOTE, `eval_threshold=0.5`):**\n",
        "- **Accuracy**: Started at ~0.0675, increased to ~0.7153 by round 5.\n",
        "- **Precision**: Started at ~0.0471, ended at ~0.1223 by round 5.\n",
        "- **Recall**: Started at ~0.94, ended at ~0.78 by round 5.\n",
        "- **F1**: Started at ~0.0898, ended at ~0.2114 by round 5.\n",
        "- **ROC AUC**: Started at ~0.5505, increased to ~0.8264 by round 5.\n",
        "\n",
        "**Current Run (with SMOTE, `eval_threshold=0.7`):**\n",
        "- **Accuracy**: Started at ~0.9511, decreased to ~0.8611 by round 5.\n",
        "- **Precision**: Started at 0.0, increased to ~0.2013 by round 5.\n",
        "- **Recall**: Started at 0.0, increased to ~0.62 by round 5.\n",
        "- **F1**: Started at 0.0, increased to ~0.3039 by round 5.\n",
        "- **ROC AUC**: Started at ~0.6301, increased to ~0.8366 by round 5.\n",
        "\n",
        "**Impact of SMOTE and Higher `eval_threshold`:**\n",
        "\n",
        "1.  **Accuracy**: The accuracy is generally higher in the current run, starting very high (~0.95) and staying relatively high (~0.86) by the end. However, this high accuracy at the beginning (round 0) might be misleading as the precision and recall are 0, suggesting the model is predicting mostly the majority class. With the higher `eval_threshold`, more instances need to have a higher predicted probability to be classified as positive, which can lead to higher specificity (correctly identifying negatives) and thus higher overall accuracy if the negative class is dominant.\n",
        "\n",
        "2.  **Precision**: Precision significantly increased from ~0.1223 in the previous run to ~0.2013 in the current run. This indicates that when the model predicts a positive case, it is more likely to be correct. The higher `eval_threshold` of 0.7 contributes to this by making the model more conservative in its positive predictions.\n",
        "\n",
        "3.  **Recall**: Recall decreased from ~0.78 in the previous run to ~0.62 in the current run. While the previous run had a very high recall, it also had very low precision, meaning it caught many positive cases but also had many false positives. The current setup sacrifices some recall for better precision.\n",
        "\n",
        "4.  **F1-score**: The F1-score, which is the harmonic mean of precision and recall, improved from ~0.2114 to ~0.3039. This suggests a better balance between precision and recall, indicating a more effective model overall, especially in handling the imbalanced dataset.\n",
        "\n",
        "5.  **ROC AUC**: The ROC AUC score saw a slight improvement, increasing from ~0.8264 to ~0.8366. This metric is robust to class imbalance and changes in the prediction threshold, and its improvement suggests a better overall discriminative ability of the model.\n",
        "\n",
        "**Conclusion:**\n",
        "Applying SMOTE to the training data helped address the class imbalance, leading to a more balanced trade-off between precision and recall. The higher `eval_threshold` of 0.7 made the model more selective in its positive predictions, which improved precision and F1-score, even at the cost of some recall. The overall performance, as indicated by the F1-score and ROC AUC, improved, suggesting that SMOTE and adjusting the evaluation threshold were beneficial for this imbalanced classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "707de0d0"
      },
      "source": [
        "### Interpretation of Metrics after SMOTE and Higher Evaluation Threshold\n",
        "\n",
        "Comparing the results from the previous run (without SMOTE and with `eval_threshold=0.5`) to the current run (with SMOTE and `eval_threshold=0.7`):\n",
        "\n",
        "**Previous Run (without SMOTE, `eval_threshold=0.5`):**\n",
        "- **Accuracy**: Started at ~0.0675, increased to ~0.7153 by round 5.\n",
        "- **Precision**: Started at ~0.0471, ended at ~0.1223 by round 5.\n",
        "- **Recall**: Started at ~0.94, ended at ~0.78 by round 5.\n",
        "- **F1**: Started at ~0.0898, ended at ~0.2114 by round 5.\n",
        "- **ROC AUC**: Started at ~0.5505, increased to ~0.8264 by round 5.\n",
        "\n",
        "**Current Run (with SMOTE, `eval_threshold=0.7`):**\n",
        "- **Accuracy**: Started at ~0.9511, decreased to ~0.8611 by round 5.\n",
        "- **Precision**: Started at 0.0, increased to ~0.2013 by round 5.\n",
        "- **Recall**: Started at 0.0, increased to ~0.62 by round 5.\n",
        "- **F1**: Started at 0.0, increased to ~0.3039 by round 5.\n",
        "- **ROC AUC**: Started at ~0.6301, increased to ~0.8366 by round 5.\n",
        "\n",
        "**Impact of SMOTE and Higher `eval_threshold`:**\n",
        "\n",
        "1.  **Accuracy**: The accuracy is generally higher in the current run, starting very high (~0.95) and staying relatively high (~0.86) by the end. However, this high accuracy at the beginning (round 0) might be misleading as the precision and recall are 0, suggesting the model is predicting mostly the majority class. With the higher `eval_threshold`, more instances need to have a higher predicted probability to be classified as positive, which can lead to higher specificity (correctly identifying negatives) and thus higher overall accuracy if the negative class is dominant.\n",
        "\n",
        "2.  **Precision**: Precision significantly increased from ~0.1223 in the previous run to ~0.2013 in the current run. This indicates that when the model predicts a positive case, it is more likely to be correct. The higher `eval_threshold` of 0.7 contributes to this by making the model more conservative in its positive predictions.\n",
        "\n",
        "3.  **Recall**: Recall decreased from ~0.78 in the previous run to ~0.62 in the current run. While the previous run had a very high recall, it also had very low precision, meaning it caught many positive cases but also had many false positives. The current setup sacrifices some recall for better precision.\n",
        "\n",
        "4.  **F1-score**: The F1-score, which is the harmonic mean of precision and recall, improved from ~0.2114 to ~0.3039. This suggests a better balance between precision and recall, indicating a more effective model overall, especially in handling the imbalanced dataset.\n",
        "\n",
        "5.  **ROC AUC**: The ROC AUC score saw a slight improvement, increasing from ~0.8264 to ~0.8366. This metric is robust to class imbalance and changes in the prediction threshold, and its improvement suggests a better overall discriminative ability of the model.\n",
        "\n",
        "**Conclusion:**\n",
        "Applying SMOTE to the training data helped address the class imbalance, leading to a more balanced trade-off between precision and recall. The higher `eval_threshold` of 0.7 made the model more selective in its positive predictions, which improved precision and F1-score, even at the cost of some recall. The overall performance, as indicated by the F1-score and ROC AUC, improved, suggesting that SMOTE and adjusting the evaluation threshold were beneficial for this imbalanced classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba265297"
      },
      "source": [
        "### Interpretation of Metrics after SMOTE and Higher Evaluation Threshold\n",
        "\n",
        "Comparing the results from the previous run (without SMOTE and with `eval_threshold=0.5`) to the current run (with SMOTE and `eval_threshold=0.7`):\n",
        "\n",
        "**Previous Run (without SMOTE, `eval_threshold=0.5`):**\n",
        "- **Accuracy**: Started at ~0.0675, increased to ~0.7153 by round 5.\n",
        "- **Precision**: Started at ~0.0471, ended at ~0.1223 by round 5.\n",
        "- **Recall**: Started at ~0.94, ended at ~0.78 by round 5.\n",
        "- **F1**: Started at ~0.0898, ended at ~0.2114 by round 5.\n",
        "- **ROC AUC**: Started at ~0.5505, increased to ~0.8264 by round 5.\n",
        "\n",
        "**Current Run (with SMOTE, `eval_threshold=0.7`):**\n",
        "- **Accuracy**: Started at ~0.9511, decreased to ~0.8611 by round 5.\n",
        "- **Precision**: Started at 0.0, increased to ~0.2013 by round 5.\n",
        "- **Recall**: Started at 0.0, increased to ~0.62 by round 5.\n",
        "- **F1**: Started at 0.0, increased to ~0.3039 by round 5.\n",
        "- **ROC AUC**: Started at ~0.6301, increased to ~0.8366 by round 5.\n",
        "\n",
        "**Impact of SMOTE and Higher `eval_threshold`:**\n",
        "\n",
        "1.  **Accuracy**: The accuracy is generally higher in the current run, starting very high (~0.95) and staying relatively high (~0.86) by the end. However, this high accuracy at the beginning (round 0) might be misleading as the precision and recall are 0, suggesting the model is predicting mostly the majority class. With the higher `eval_threshold`, more instances need to have a higher predicted probability to be classified as positive, which can lead to higher specificity (correctly identifying negatives) and thus higher overall accuracy if the negative class is dominant.\n",
        "\n",
        "2.  **Precision**: Precision significantly increased from ~0.1223 in the previous run to ~0.2013 in the current run. This indicates that when the model predicts a positive case, it is more likely to be correct. The higher `eval_threshold` of 0.7 contributes to this by making the model more conservative in its positive predictions.\n",
        "\n",
        "3.  **Recall**: Recall decreased from ~0.78 in the previous run to ~0.62 in the current run. While the previous run had a very high recall, it also had very low precision, meaning it caught many positive cases but also had many false positives. The current setup sacrifices some recall for better precision.\n",
        "\n",
        "4.  **F1-score**: The F1-score, which is the harmonic mean of precision and recall, improved from ~0.2114 to ~0.3039. This suggests a better balance between precision and recall, indicating a more effective model overall, especially in handling the imbalanced dataset.\n",
        "\n",
        "5.  **ROC AUC**: The ROC AUC score saw a slight improvement, increasing from ~0.8264 to ~0.8366. This metric is robust to class imbalance and changes in the prediction threshold, and its improvement suggests a better overall discriminative ability of the model.\n",
        "\n",
        "**Conclusion:**\n",
        "Applying SMOTE to the training data helped address the class imbalance, leading to a more balanced trade-off between precision and recall. The higher `eval_threshold` of 0.7 made the model more selective in its positive predictions, which improved precision and F1-score, even at the cost of some recall. The overall performance, as indicated by the F1-score and ROC AUC, improved, suggesting that SMOTE and adjusting the evaluation threshold were beneficial for this imbalanced classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30a8f09d"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the findings regarding SMOTE's effectiveness on precision and discuss any trade-offs observed with other metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbb6191b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The effectiveness of SMOTE on precision, combined with a higher evaluation threshold, led to a significant improvement in precision (from 0.1223 to 0.2013). This was achieved by making the model more conservative in its positive predictions.\n",
        "\n",
        "However, this improvement came with a trade-off in recall, which decreased from 0.78 to 0.62. This indicates that while the model's positive predictions are more accurate, it now identifies a smaller proportion of the actual positive cases. Despite the drop in recall, the F1-score, which balances precision and recall, improved from 0.2114 to 0.3039, suggesting a better overall balance and effectiveness for the imbalanced dataset.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Precision significantly improved:** Precision increased from approximately 0.1223 (without SMOTE, `eval_threshold=0.5`) to 0.2013 (with SMOTE, `eval_threshold=0.7`), indicating more reliable positive predictions.\n",
        "*   **Recall experienced a trade-off:** Recall decreased from approximately 0.78 to 0.62, meaning the model missed more true positive cases in exchange for higher precision.\n",
        "*   **F1-score showed overall improvement:** The F1-score, a harmonic mean of precision and recall, improved from 0.2114 to 0.3039, suggesting a better balance between precision and recall after applying SMOTE and adjusting the threshold.\n",
        "*   **Accuracy increased notably:** Accuracy rose from 0.7153 to 0.8611, indicating more correct predictions overall, likely due to increased specificity from the higher `eval_threshold`.\n",
        "*   **ROC AUC had a slight gain:** The ROC AUC score saw a minor improvement from 0.8264 to 0.8366, reflecting a slightly better overall discriminative ability of the model.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The combination of SMOTE and an increased evaluation threshold effectively optimized the model for higher precision, which is beneficial in scenarios where minimizing false positives is critical, even at the cost of some recall.\n",
        "*   Further hyperparameter tuning for SMOTE or exploring other oversampling/undersampling techniques, along with an optimized `eval_threshold` (e.g., using a precision-recall curve), could potentially achieve an even better balance between precision and recall without significant trade-offs.\n"
      ]
    }
  ]
}